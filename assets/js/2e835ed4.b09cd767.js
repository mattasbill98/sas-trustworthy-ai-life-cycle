"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[241],{4424:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>l,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"train-model","title":"4. Train and assess model","description":"Train and assess a set of models to help find the best model for production.","source":"@site/docs/4-train-model.md","sourceDirName":".","slug":"/train-model","permalink":"/sas-trustworthy-ai-life-cycle/train-model","draft":false,"unlisted":false,"editUrl":"https://github.com/sassoftware/sas-trustworthy-ai-life-cycle/tree/main/website/docs/4-train-model.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"defaultSidebar","previous":{"title":"3. Prepare and assess data","permalink":"/sas-trustworthy-ai-life-cycle/prepare-and-assess-data"},"next":{"title":"5. Test model","permalink":"/sas-trustworthy-ai-life-cycle/test-model"}}');var i=t(4848),a=t(8453);const l={sidebar_position:5},r="4. Train and assess model",o={},d=[{value:"4.1 Train models",id:"41-train-models",level:2},{value:"4.2 Document model evaluation metrics",id:"42-document-model-evaluation-metrics",level:2},{value:"4.3 Assess model bias",id:"43-assess-model-bias",level:2},{value:"4.3.1 Does the model need a bias evaluation?",id:"431-does-the-model-need-a-bias-evaluation",level:3},{value:"4.3.2 Compare and document subgroup model performance",id:"432-compare-and-document-subgroup-model-performance",level:3},{value:"4.3.3 Compare and document average model predictions per subgroup",id:"433-compare-and-document-average-model-predictions-per-subgroup",level:3},{value:"4.3.4 Bias metrics differences approval",id:"434-bias-metrics-differences-approval",level:3},{value:"4.4 Assess model explainability",id:"44-assess-model-explainability",level:2},{value:"4.4.1 Is model explainability important?",id:"441-is-model-explainability-important",level:3},{value:"4.4.2 Document model explainability",id:"442-document-model-explainability",level:3},{value:"4.4.3 Model explanations approval",id:"443-model-explanations-approval",level:3}];function c(e){const s={a:"a",blockquote:"blockquote",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"4-train-and-assess-model",children:"4. Train and assess model"})}),"\n",(0,i.jsx)(s.p,{children:"Train and assess a set of models to help find the best model for production."}),"\n",(0,i.jsx)(s.h2,{id:"41-train-models",children:"4.1 Train models"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Train and fine-tune several models. Document a set of promising models. Note the location of the models and modeling assets:"]}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(s.h2,{id:"42-document-model-evaluation-metrics",children:"4.2 Document model evaluation metrics"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Document all fit statistics used for model evaluation. Note resulting values for promising models."]}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(s.h2,{id:"43-assess-model-bias",children:"4.3 Assess model bias"}),"\n",(0,i.jsx)(s.h3,{id:"431-does-the-model-need-a-bias-evaluation",children:"4.3.1 Does the model need a bias evaluation?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Does the model require a bias evaluation, based on the implications for the use of the AI system, among other factors? For example, the AI system needs bias evaluation if it could perform differently under varying conditions."]}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Yes. If selected, continue to the next step."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","No. If selected, move to step ",(0,i.jsx)(s.a,{href:"#434-bias-metrics-differences-approval",children:"4.3.4"}),"."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If applicable, add any additional details:"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"432-compare-and-document-subgroup-model-performance",children:"4.3.2 Compare and document subgroup model performance"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Calculate and compare model performance values and additional fairness metrics for each protected class or subgroup.\nSubgroups are often protected classes, or groups of people that are legally protected from discrimination based on a shared characteristic, such as a disability, sexual orientation, or race.\nHowever, subgroups could also be important groups within the data based on the model use case, even though they are not legally defined as protected classes.\nTo calculate model performance values, use model performance metrics defined by your organization in the testing strategy outlined in ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/document-project",children:"step 2.1.6"}),".\nFairness metrics might include equal opportunity, demographic parity, predictive parity, equal accuracy, or equalized odds."]}),"\n",(0,i.jsx)(s.p,{children:"Document or save results."}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"433-compare-and-document-average-model-predictions-per-subgroup",children:"4.3.3 Compare and document average model predictions per subgroup"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Calculate and compare average model predictions for each protected class or subgroup."]}),"\n",(0,i.jsx)(s.p,{children:"Document or save results."}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"434-bias-metrics-differences-approval",children:"4.3.4 Bias metrics differences approval"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model owner"}),": Is the documentation provided by the model developer satisfactory? If bias evaluation is required, are the differences in bias metric values satisfactory?"]}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Yes"]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","No"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If no, which areas need additional review?"}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Retrain models with new data. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/prepare-and-assess-data",children:"step 3"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Fine-tune the models with existing data. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/train-model",children:"step 4"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Set a new champion model. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/test-model",children:"step 5"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Update the project documentation. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/document-project",children:"step 2"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," End the workflow. If selected, depreciate the project and update ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/document-project",children:"step 2.1.1"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Move forward with the model. If selected, provide additional details or a justification, and then continue to the next step."]}),"\n"]}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"44-assess-model-explainability",children:"4.4 Assess model explainability"}),"\n",(0,i.jsx)(s.h3,{id:"441-is-model-explainability-important",children:"4.4.1 Is model explainability important?"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Is model explainability or interpretability important for this use case?\nAn explainable model allows human users to comprehend and trust the results of the output generated by the model. Explainability is important in most use cases."]}),"\n",(0,i.jsx)(s.p,{children:"Is explainability important for this use case?"}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Yes. If selected, continue to the next step."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","No. If selected, move to step ",(0,i.jsx)(s.a,{href:"#443-model-explanations-approval",children:"4.4.3"}),"."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If applicable, add any additional details:"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"442-document-model-explainability",children:"4.4.2 Document model explainability"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model developer"}),": Document model explainability method and results.\nEnsure that explainability information is made available to the model end user. Select the most appropriate explainability methods for the use case and model type.\nSAS Viya includes explainability tools such as Partial Dependence (PD) plots, Individual Conditional Expectation (ICE) plots, Local Interpretable Model-Agnostic Explanation (LIME), and Kernel Shapley values (Kernel SHAP). These techniques are model-agnostic, which means that these techniques can be applied to any model that is generated by a supervised learning node."]}),"\n",(0,i.jsx)(s.p,{children:"Document or save results."}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"443-model-explanations-approval",children:"4.4.3 Model explanations approval"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Model owner"}),": Is the documentation provided by the model developer satisfactory? If explainability is required, are the models' level of explainability acceptable?"]}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","Yes"]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," ","No"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If no, which areas need additional review?"}),"\n",(0,i.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Retrain models with new data. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/prepare-and-assess-data",children:"step 3"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Fine-tune the models with existing data. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/train-model",children:"step 4"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Set a new champion model. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/test-model",children:"step 5"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Update the project documentation. If selected, return to ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/document-project",children:"step 2"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," End the workflow. If selected, depreciate the project and update ",(0,i.jsx)(s.a,{href:"/sas-trustworthy-ai-life-cycle/document-project",children:"step 2.1.1"}),"."]}),"\n",(0,i.jsxs)(s.li,{className:"task-list-item",children:[(0,i.jsx)(s.input,{type:"checkbox",disabled:!0})," "," Move forward with the model. If selected, provide additional details or a justification, and then continue to the next step."]}),"\n"]}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n"]})]})}function p(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,s,t)=>{t.d(s,{R:()=>l,x:()=>r});var n=t(6540);const i={},a=n.createContext(i);function l(e){const s=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),n.createElement(a.Provider,{value:s},e.children)}}}]);